<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148984682-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-148984682-2');
  </script>
  
  <title>Kai Zhang</title>
  
  <meta name="author" content="Kai Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
            <td style="padding:2.5%;width:25%;max-width:25%">
              <a href="kai.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="kai.jpg" class="hoverZoomLink"></a>
            </td>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Kai Zhang</name>
                </p>
                <p style="text-align:center">
                  <a href="mailto:kz298@cornell.edu">Email</a> &nbsp/&nbsp
                  <a href="https://drive.google.com/file/d/1i8ed1PrsZxJzS3QYd19mvuLiuQ2v9LHG/view?usp=sharing">CV</a>  &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/kai-zhang-53910214a/">LinkedIn</a> &nbsp/&nbsp
                  <a href="https://github.com/Kai-46/">Github</a>
                </p>

                <p>I am a PhD student at <a href="https://tech.cornell.edu/">Cornell University</a>, where I work with <a href="http://www.cs.cornell.edu/~snavely/">Prof. Noah Snavely</a>. 
                  Before PhD, I did my undergraduate at <a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a>. I'm very interested in automatic 3D content creation from images, and other 3D vision problems, including inverse graphics, novel view synthesis, computational photography, reconstruction, and depth sensing, etc.
                </p>   
                <p style="color:magenta">
                <em>I'm now seeking industrial research scientist / engineer positions starting Jan. 2022. Feel free to drop me an email if my expertise might be a good fit for your teams! </em>
                </p>
              </td>
            </tr>
          </tbody>
        </table>
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">          
          <tbody>
            <tr>
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                <heading>Research</heading>
              </td>
            </tr>
            
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                [6]&nbsp&nbsp<papertitle>ARF: Artistic Radiance Fields</papertitle>
                <br>
                <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a>,
                <a href="https://home.ttic.edu/~nickkolkin/home.html">Nick Kolkin</a>,
                <a href="https://sai-bi.github.io/">Sai Bi</a>,
                <a href="https://www.cs.cornell.edu/~fujun/">Fujun Luan</a>,
                <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>,
                <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>,
                <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
                <br>
                <em>ECCV</em>, 2022&nbsp
                <br>
                <a href="https://arxiv.org/abs/2206.06360">arxiv</a> /
                <a href="https://www.cs.cornell.edu/projects/arf/">project page</a> /
                <a href="https://github.com/Kai-46/ARF-svox2">code</a>
                <br>
                We propose to stylize the appearance of NeRF using Nearest Neighbor Feature Matching (NNFM) style loss to create artistic 3D contents.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                [5]&nbsp&nbsp<papertitle>IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images</papertitle>
                <br>
                <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a>,
                <a href="https://www.cs.cornell.edu/~fujun/">Fujun Luan</a>,
                <a href="https://www.cs.cornell.edu/~zl548/">Zhengqi Li</a>,    
                <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
                <br>
                <em>CVPR</em>, 2022 (Oral)&nbsp
                <br>
                <a href="https://arxiv.org/abs/2204.02232">arxiv</a> /
                <a href="https://kai-46.github.io/IRON-website/">project page</a> /
                <a href="https://github.com/Kai-46/IRON">code</a>
                <br>
                We propose a neural inverse rendering pipeline called IRON that operates on photometric images and outputs high-quality 3D content in the format of triangle meshes and material textures readily deployable in existing graphics pipelines.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                [4]&nbsp&nbsp<papertitle>PhySG: Inverse Rendering with Spherical Gaussians for Physics-based Material Editing and Relighting</papertitle>
                <br>
                <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a><sup>*</sup>,
                <a href="https://www.cs.cornell.edu/~fujun/">Fujun Luan<sup>*</sup></a>,
                <a href="https://www.cs.cornell.edu/~qqw/">Qianqian Wang</a>,    
                <a href="https://www.cs.cornell.edu/~kb/">Kavita Bala</a>,
                <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a> (<sup>*</sup>Equal contribution)
                <br>
                <em>CVPR</em>, 2021 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2104.00674">arxiv</a> /
                <a href="https://kai-46.github.io/PhySG-website/">project page</a> /
                <a href="https://github.com/Kai-46/PhySG/">code</a>
                <br>
                We propose an end-to-end differentiable rendering pipeline that jointly estimates geometry, material and lighting from multi-view images from scratch. It enables not just novel view synthesis, but also relighting and material editing.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [3]&nbsp&nbsp<papertitle>NeRF++: Analyzing and Improving Neural Radiance Fields</papertitle>
                  <br>
                  <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a>,
                  <a href="https://griegler.github.io/">Gernot Riegler</a>,
                  <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>,
                  <a href="http://vladlen.info/">Vladlen Koltun</a>
                  <br>
                  <em>arXiv preprint</em>, 2020 &nbsp
                  <br>
                  <a href="http://arxiv.org/abs/2010.07492">arxiv</a> /
                  <a href="https://github.com/Kai-46/nerfplusplus">code</a> 
                  <br>
                  We analyze the shape-radiance ambiguity in NeRF, and extend NeRF to work with 360 unbounded scenes. At the core of the method is the Inverted Sphere Parametrization (ISP) contracting an unbounded space to a bounded one.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                [2]&nbsp&nbsp<papertitle>Depth Sensing Beyond LiDAR Range</papertitle>
                <br>
                <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a>,
                Jiaxin Xie,
                <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>,
                <a href="https://cqf.io/">Qifeng Chen</a>
                <br>
                <em>CVPR</em>, 2020 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2004.03048">arxiv</a> /
                <a href="https://kai-46.github.io/DepthSensing/">project page</a> /
                <a href="https://github.com/Kai-46/DepthSensingBeyondLiDARRange">code</a> 
                <br>
                We propose a novel cost-effective camera-based solution to sense the depth of distant objects that are not reachable by typical LiDARs. This can be particularly helpful for heavily-weighted autonomous trucks.
              </td>
            </tr>
          
            <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
              <td style="padding-top:0px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [1]&nbsp&nbsp<papertitle>Leveraging Vision Reconstruction Pipelines for Satellite Imagery</papertitle>
                  <br>
                  <a href="https://kai-46.github.io/website/"><strong>Kai Zhang</strong></a>,
                  <a>Jin Sun</a>,
                  <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
                  <br>
                  <em>ICCV 3DRW Workshop</em>, 2019 &nbsp
                  <br>
                  <a href="https://arxiv.org/abs/1910.02989">arxiv</a> /
                  <a href="https://kai-46.github.io/VisSat/">project page</a> /
                  <a href="https://kai-46.github.io/VisSat/#code">code</a> 
                  <br>
                  We approximate satellite-specific RPC cameras with perspective cameras, and adapt vision reconstruction pipelines (SfM+MVS) such that they can also process satellite images with competitive accuracy and increased scalability.
              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <heading>Services</heading>
                  <p>
                    Internships: Adobe (2022 Summer), Intel (2021 Summer, 2020 Summer), HKUST (2019 Summer), ICL (2016 Summer) <br>
                    Paper reviewer: ICCV, CVPR, TVGG, TPAMI, SIGGRAPH<br>
                    Seminar co-organizer: Cornell Graphics and Vision Seminar, 2021 Fall<br>
                    Talk speaker: Graphics And Mixed Environment Seminar (GAMES), 2021<br>
                    Teaching assistant: Deep Learning, 2022 Spring; Applied Machine Learning, 2021 Fall, 2020 Fall; Introduction to Computer Vision, 2020 Spring, 2019 Spring
                  </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                <heading>Open-source</heading>
                  <p>
                    In my spare time, Iâ€™ve been actively contributing to building an all-in-one open-source satellite stereo
                    toolbox called <a href="https://github.com/Kai-46/SatelliteSfM">SatelliteSfM</a>, in order to facilitate latest advances in  3D computer vision to satellite domain.
                  </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Kudos to <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing his website template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
